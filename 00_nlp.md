# 自然语言处理简介

## 什么是自然语言处理

简单地说，自然语言处理（Natural Language Processing，简称NLP）就是用计算机来处理、理解以及运用人类语言(如中文、英文等)，它属于人工智能的一个分支，是计算机科学与语言学的交叉学科，又常被称为计算语言学。由于自然语言是人类区别于其他动物的根本标志。没有语言，人类的思维也就无从谈起，所以自然语言处理体现了人工智能的最高任务与境界，也就是说，只有当计算机具备了处理自然语言的能力时，机器才算实现了真正的智能。

从研究内容来看，自然语言处理包括语法分析、语义分析、篇章理解等。从应用角度来看，自然语言处理具有广泛的应用前景。特别是在信息时代，自然语言处理的应用包罗万象，例如：机器翻译、手写体和印刷体字符识别、语音识别及文语转换、信息检索、信息抽取与过滤、文本分类与聚类、舆情分析和观点挖掘等，它涉及与语言处理相关的数据挖掘、机器学习、知识获取、知识工程、人工智能研究和与语言计算相关的语言学研究等。

值得一提的是，自然语言处理的兴起与机器翻译这一具体任务有着密切联系。机器翻译指的是利用计算机自动地将一种自然语言翻译为另外一种自然语言。例如自动将英文“I like Beijing Tiananmen Square”翻译为“我爱北京天安门”，或者反过来将“我爱北京天安门”翻译为“I like Beijing Tiananmen Square”。由于人工进行翻译需要训练有素的双语专家，翻译工作非常耗时耗力。更不用说需要翻译一些专业领域文献时，还需要翻译者了解该领域的基本知识。世界上有超过几千种语言，而仅联合国的工作语言就有六种之多。如果能够通过机器翻译准确地进行语言间的翻译，将大大提高人类沟通和了解的效率。

《圣经》里有一个故事说巴比伦人想建造一座塔直通天堂。建塔的人都说着同一种语言，心意相通、齐心协力。上帝看到人类竟然敢做这种事情，就让他们的语言变得不一样。因为人们听不懂对方在讲什么，于是大家整天吵吵闹闹，无法继续建塔。后来人们把这座塔叫作巴别塔，而“巴别”的意思就是“分歧”。虽然巴别塔停建了，但一个梦想却始终萦绕在人们心中：人类什么时候才能拥有相通的语言，重建巴别塔呢？机器翻译被视为“重建巴别塔”的伟大创举。假如能够实现不同语言之间的机器翻译，我们就可以理解世界上任何人说的话，与他们进行交流和沟通，再也不必为相互不能理解而困扰。

事实上，“人工智能”被作为一个研究问题正式提出来的时候，创始人把计算机国际象棋和机器翻译作为两个标志性的任务，认为只要国际象棋系统能够打败人类世界冠军，机器翻译系统达到人类翻译水平，就可以宣告人工智能的胜利。四十年后的1997年，IBM公司的深蓝超级计算机已经能够打败国际象棋世界冠军卡斯帕罗夫。而机器翻译到现在仍无法与人类翻译水平相比，从此可以看出自然语言处理有多么困难！

自然语言处理兴起于美国。第二次世界大战之后，二十世纪五十年代，当电子计算机还在襁褓之中时，利用计算机处理人类语言的想法就已经出现。当时，美国希望能够利用计算机将大量俄语材料自动翻译成英语，以窥探苏联科技的最新发展。研究者从破译军事密码中得到启示，认为不同的语言只不过是对“同一语义”的不同编码而已，从而想当然地认为可以采用译码技术像破译密码一样“破译”这些语言。

1954年1月7日，美国乔治敦大学和IBM公司合作实验成功地将超过60句俄语自动翻译成英语。虽然当时的这个机器翻译系统非常简单，仅仅包含6个语法规则和250个词，但由于媒体的广泛报道，纷纷认为这是一个巨大的进步，导致美国政府备受鼓舞，加大了对自然语言处理研究的投资。实验完成者也当即自信地撰文称，在三到五年之内就能够完全解决从一种语言到另一种语言的自动翻译问题。他们认为只要制定好各种翻译规则，通过大量规则的堆砌就能够完美地实现语言间的自动翻译。

然而，事实是理解人类语言远比破译密码要复杂得多，因此研究进展非常缓慢。1966年的一份研究报告总结发现，经过十年之久的研究，结果远远未能达到预期，因此支持资金急剧下降，使自然语言处理（特别是机器翻译）的研究陷入长达二十年的低潮。直到二十世纪八十年代，随着电子计算机的计算能力的飞速提高和制造成本的大幅下降，研究者又开始重新关注自然语言处理这个极富挑战的研究领域。三十年沧海桑田，此时研究者已经认识到简单的语言规则的堆砌无法实现对人类语言的真正理解。研究发现，通过对大量的文本数据的自动学习和统计，能够更好地解决自然语言处理问题，如语言的自动翻译。这一思想被称为自然语言处理的统计学习模型，至今方兴未艾。

那么，自然语言处理到底存在哪些主要困难或挑战，吸引那么多研究者几十年如一日孜孜不倦地探索解决之道呢？

## 自然语言处理的主要困难

自然语言处理的困难可以罗列出来很多，不过关键在于消除歧义问题，如词法分析、句法分析、语义分析等过程中存在的歧义问题，简称为消歧。而正确的消歧需要大量的知识，包括语言学知识（如词法、句法、语义、上下文等）和世界知识（与语言无关）。这带来自然语言处理的两个主要困难。

首先，语言中充满了大量的歧义，这主要体现在词法、句法及语义三个层次上。歧义的产生是由于自然语言所描述的对象――人类活动非常复杂，而语言的词汇和句法规则又是有限的，这就造成同一种语言形式可能具有多种含义。

例如单词定界问题是属于词法层面的消歧任务。在口语中，词与词之间通常是连贯说出来的。在书面语中，中文等语言也没有词与词之间的边界。由于单词是承载语义的最小单元，要解决自然语言处理，单词的边界界定问题首当其冲。特别是中文文本通常由连续的字序列组成，词与词之间缺少天然的分隔符，因此中文信息处理比英文等西方语言多一步工序，即确定词的边界，我们称为“中文自动分词”任务。通俗的说就是要由计算机在词与词之间自动加上分隔符，从而将中文文本切分为独立的单词。例如一个句子“今天天气晴朗”的带有分隔符的切分文本是“今天|天气|晴朗”。中文自动分词处于中文自然语言处理的底层，是公认的中文信息处理的第一道工序，扮演着重要的角色，主要存在新词发现和歧义切分等问题。我们注意到：正确的单词切分取决于对文本语义的正确理解，而单词切分又是理解语言的最初的一道工序。这样的一个“鸡生蛋、蛋生鸡”的问题自然成了（中文）自然语言处理的第一条拦路虎。

其他级别的语言单位也存在着各种歧义问题。例如在短语级别上，“进口彩电”可以理解为动宾关系（从国外进口了一批彩电），也可以理解为偏正关系（从国外进口的彩电）。又如在句子级别上，“做手术的是她的父亲”可以理解为她父亲生病了需要做手术，也可以理解为她父亲是医生，帮别人做手术。总之，同样一个单词、短语或者句子有多种可能的理解，表示多种可能的语义。如果不能解决好各级语言单位的歧义问题，我们就无法正确理解语言要表达的意思。

另外一个方面，消除歧义所需要的知识在获取、表达以及运用上存在困难。由于语言处理的复杂性，合适的语言处理方法和模型难以设计。

例如上下文知识的获取问题。在试图理解一句话的时候，即使不存在歧义问题，我们也往往需要考虑上下文的影响。所谓的“上下文”指的是当前所说这句话所处的语言环境，例如说话人所处的环境，或者是这句话的前几句话或者后几句话，等等。假如当前这句话中存在指代词的时候，我们需要通过这句话前面的句子来推断这个指代词是指的什么。我们以“小明欺负小亮，因此我批评了他”为例。在其中的第二句话中的“他”是指代“小明”还是“小亮”呢？要正确理解这句话，我们就要理解上句话“小明欺负小亮”意味着“小明”做得不对，因此第二句中的“他”应当指代的是“小明”。由于上下文对于当前句子的暗示形式是多种多样的，因此如何考虑上下文影响问题是自然语言处理中的主要困难之一。

再如背景知识问题。 正确理解人类语言还要有足够的背景知识。举一个简单的例子，在机器翻译研究的初期，人们经常举一个例子来说明机器翻译任务的艰巨性。在英语中“The spirit is willing but the flesh is weak.”，意思是“心有余而力不足”。但是当时的某个机器翻译系统将这句英文翻译到俄语，然后再翻译回英语的时候，却变成了“The Voltka is strong but the meat is rotten.”，意思是“伏特加酒是浓的，但肉却腐烂了”。从字面意义上看，“spirit”（烈性酒）与“Voltka”（伏特加）对译似无问题，而“flesh”和“meat”也都有肉的意思。那么这两句话在意义上为什么会南辕北辙呢？关键的问题就在于在翻译的过程中，机器翻译系统对于英语成语并无了解，仅仅是从字面上进行翻译，结果自然失之毫厘，差之千里。

从上面的两个方面的主要困难，我们看到自然语言处理这个难题的根源就是人类语言的复杂性和语言描述的外部世界的复杂性。人类语言承担着人类表达情感、交流思想、传播知识等重要功能，因此需要具备强大的灵活性和表达能力，而理解语言所需要的知识又是无止境的。那么目前人们是如何尝试进行自然语言处理的呢？

## 自然语言处理的发展趋势

目前，人们主要通过两种思路来进行自然语言处理，一种是基于规则的理性主义，另外一种是基于统计的经验主义。理性主义方法认为，人类语言主要是由语言规则来产生和描述的，因此只要能够用适当的形式将人类语言规则表示出来，就能够理解人类语言，并实现语言之间的翻译等各种自然语言处理任务。而经验主义方法则认为，从语言数据中获取语言统计知识，有效建立语言的统计模型。因此只要能够有足够多的用于统计的语言数据，就能够理解人类语言。然而，当面对现实世界充满模糊与不确定性时，这两种方法都面临着各自无法解决的问题。例如，人类语言虽然有一定的规则，但是在真实使用中往往伴随大量的噪音和不规范性。理性主义方法的一大弱点就是鲁棒性差，只要与规则稍有偏离便无法处理。而对于经验主义方法而言，又不能无限地获取语言数据进行统计学习，因此也不能够完美地理解人类语言。二十世纪八十年代以来的趋势就是，基于语言规则的理性主义方法不断受到质疑，大规模语言数据处理成为目前和未来一段时期内自然语言处理的主要研究目标。统计学习方法越来越受到重视，自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。

迈进二十一世纪，我们已经进入了以互联网为主要标志的海量信息时代，这些海量信息大部分是以自然语言表示的。一方面，海量信息也为计算机学习人类语言提供了更多的“素材”，另一方面，这也为自然语言处理提供了更加宽广的应用舞台。例如，作为自然语言处理的重要应用，搜索引擎逐渐成为人们获取信息的重要工具，涌现出以百度、谷歌等为代表的搜索引擎巨头；机器翻译也从实验室走入寻常百姓家，谷歌、百度等公司都提供了基于海量网络数据的机器翻译和辅助翻译工具；基于自然语言处理的中文（输入法如搜狗、微软、谷歌等输入法）成为计算机用户的必备工具；带有语音识别的计算机和手机也正大行其道，协助用户更有效地工作学习。总之，随着互联网的普及和海量信息的涌现，自然语言处理正在人们的日常生活中扮演着越来越重要的作用。

然而，我们同时面临着一个严峻事实，那就是如何有效利用海量信息已成为制约信息技术发展的一个全局性瓶颈问题。自然语言处理无可避免地成为信息科学技术中长期发展的一个新的战略制高点。同时，人们逐渐意识到，单纯依靠统计方法已经无法快速有效地从海量数据中学习语言知识，只有同时充分发挥基于规则的理性主义方法和基于统计的经验主义方法的各自优势，两者互相补充，才能够更好、更快地进行自然语言处理。

自然语言处理作为一个年龄尚不足一个世纪的新兴学科，正在进行着突飞猛进的发展。回顾自然语言处理的发展历程，并不是一帆风顺，有过低谷，也有过高潮。而现在我们正面临着新的挑战和机遇。例如，目前网络搜索引擎基本上还停留在关键词匹配，缺乏深层次的自然语言处理和理解。语音识别、文字识别、问答系统、机器翻译等目前也只能达到很基本的水平。路漫漫其修远兮，自然语言处理作为一个高度交叉的新兴学科，不论是探究自然本质还是付诸实际应用，在将来必定会有令人期待的惊喜和异常快速的发展。

## 为什么相比于计算机视觉(cv)，自然语言处理(nlp)领域的发展要缓慢？

个人观点这可能是一种误解。从图像和语言两种模态来看，对文本处理技术的大规模应用要早于计算机视觉。

将图像和语言中的处理对象做一个不太严谨的对应。如下图所示，大体上像素类似于语言中的字母；图像中的对象类似于语言中的单词/概念；图像中对象组成的场景类似于语言中的句子表达的语义；视频则类似于语言中的篇章（文章）。

在这种类比下看，NLP/IR在单词层面的处理要比CV中的图像识别简单得多，只需要做一下tokenization、lemmatization、stemming等（中文复杂一些需要额外做自动分词），就可以利用关键词匹配完成很多任务，例如信息检索、文本分类、拼写纠错、情感分析、关键词提取等等，实际上已经得到非常广泛的应用，如搜索引擎、拼音输入法、新闻分类、阅读推荐等。

而由于图像中对象的复杂性和多样性，仅在对象识别层面，甚至特定的人脸识别，还有很多技术挑战。只不过是近年来，由于深度学习对非结构数据的强大表示和学习能力，开始让对象识别走向了实用化。

而进入到更高层面，例如面向图像的场景图构建，面向文本的句法语义分析，都需要对复杂语境（上下文）的精准而强大的建模能力。所以我感觉，并非NLP发展缓慢，只是两个领域的发展节奏和阶段不同。进入高层任务后，两个领域都将面临共同的关键挑战，都可以归结为复杂语境下的多对象（图像中是不同对象，文本中是不同概念）的语义组合问题。

## 中文NLP vs 英文NLP在理论,数据处理上有什么相同和不同, 尤其是中文 NLP有什么独特的地方?

从实用文本分析技术而言：如果只做主题聚类、文本分类等任务的话，中英文最大差别就在于，中文需要做自动分词，相关工具包已经很多了，包括题主提到的Jieba，还有哈工大的LTP，北理工的ICTCLAS，还有我们组研制的THULAC。当然，在文本分类时，到底是选词还是Ngram作为特征，在SVM+BOW时代曾是个问题。进入到深度学习时代，就直接可以用基于字的神经网络模型了。

从NLP研究角度而言：中英文在词性标注、句法分析等任务上颇有差异。主要体现在英语有明显的屈折变化（单复数、时态等）而汉语缺少这些屈折变化，亦即有学者总结的“汉语重义合，英语重形合”。所以，英语里一个词被标为动词还是名词，没有太多争议；汉语里一个词应该被标为动词还是名词，例如“热爱学习”、“劳动光荣”中的“学习”、“劳动”如果按照英文语法规范应当标注为名词。著名语言学家沈家煊先生就曾提出“汉语动词和名词不分立”的理论。在句法分析层面汉语也有一些自己的特点，具体需要请教专业的语言学家解答了。

@李韶华 等答主提到中英文相关分析任务的错误率问题。之所以在一些任务上中文分析性能显著低于英文，除了中文缺少屈者变化、有更多自由度从而提升了分析难度的原因外，中文标注资源相对较少、标注质量相对较低也是关键原因之一。语言资源标注既需要语言学家和计算机学者的通力合作，需要花费大量精力和时间，在国内环境下太费力不讨好了，希望未来会有改观。

从更广阔的语言研究角度而言，我觉得中英由于各自承载了两种截然不同的人类群体的文化信息，所以在更深层的文化内涵会有更明显的分野，例如两种语言的词汇联想网络、隐喻风格等，可能会有更大的不同。也许在NLP技术日渐成熟之后，我们可以透过语言更加定量地分析两种不同文化的差异。在这方面我非常感兴趣，期待更多专家指点交流。

## 参考文献

1. 张钹. 自然语言处理的计算模型. 中文信息学报, 2007, 21(3):3-7. 
2. 冯志伟. 《统计自然语言处理》序言. 1版. 北京: 清华大学出版社, 2008.
3. 孙茂松. 语言计算:信息科学技术中长期发展的战略制高点. 语言文字应用, 2005, 3:38-40.